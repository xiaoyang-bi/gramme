{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import models\n",
    "import custom_transforms\n",
    "from datasets.sequence_folders import SequenceFolder\n",
    "from radar_eval.eval_utils import RadarEvalOdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'TITAN V'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoseResNet(\n",
       "  (encoder): ResnetEncoder(\n",
       "    (encoder): ResNetMultiImageInput(\n",
       "      (conv1): Conv2d(2, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): PoseDecoder(\n",
       "    (relu): ReLU()\n",
       "    (net): ModuleList(\n",
       "      (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_pose = torch.load(\"../checkpoints/resnet50_depth_256/02-02-09:46/exp_pose_model_best.pth.tar\")\n",
    "pose_net = models.PoseResNet(50).to(device)\n",
    "pose_net.load_state_dict(weights_pose['state_dict'], strict=False)\n",
    "pose_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading code\n",
    "mean, std = 119.4501, 6.5258 # Calculated over all dataset\n",
    "normalize = custom_transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "# train_transform = custom_transforms.Compose([\n",
    "#     custom_transforms.RandomHorizontalFlip(),\n",
    "#     custom_transforms.RandomScaleCrop(),\n",
    "#     custom_transforms.ArrayToTensor(),\n",
    "#     normalize\n",
    "# ])\n",
    "\n",
    "ds_transform = custom_transforms.Compose([custom_transforms.ArrayToTensor(), normalize])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_set = SequenceFolder(\n",
    "        '/mnt/datasets/yasin/range-azimuth',\n",
    "        transform=ds_transform,\n",
    "        seed=12344,\n",
    "        train=False,\n",
    "        sequence_length=3,\n",
    "        skip_frames=k\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vo_eval = RadarEvalOdom('/mnt/datasets/yasin/records2-23mart2020/vicon-data-subsampled/vicon-gt-test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_set, batch_size=64, shuffle=False,\n",
    "        num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_it = iter(val_loader)\n",
    "#print(val_it.next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pose_with_inv(pose_net, tgt_img, ref_imgs):\n",
    "    poses = []\n",
    "    poses_inv = []\n",
    "    for ref_img in ref_imgs:\n",
    "        poses.append(pose_net(tgt_img, ref_img))\n",
    "        poses_inv.append(pose_net(ref_img, tgt_img))\n",
    "\n",
    "    return torch.stack(poses), torch.stack(poses_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_poses = []\n",
    "all_inv_poses = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (tgt_img, ref_imgs) in enumerate(val_loader):\n",
    "        #(tgt_img, ref_imgs) = val_it.next()\n",
    "\n",
    "        tgt_img = tgt_img.to(device)\n",
    "        ref_imgs = [img.to(device) for img in ref_imgs]\n",
    "\n",
    "        poses, poses_inv = compute_pose_with_inv(pose_net, tgt_img, ref_imgs)\n",
    "\n",
    "        all_poses.append(poses)\n",
    "        all_inv_poses.append(poses_inv)\n",
    "\n",
    "        # gc.collect()\n",
    "        # torch.cuda.empty_cache()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "print(len(all_poses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_poses_t = torch.cat(all_poses, 1) # [seq_length, N, 6]\n",
    "all_inv_poses_t = torch.cat(all_inv_poses, 1) # [seq_length, N, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1953, 6])\n"
     ]
    }
   ],
   "source": [
    "print(all_poses_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0314, -0.0452,  0.0081,  0.0153,  0.0062,  0.0026],\n",
      "        [ 0.0247, -0.0373,  0.0082,  0.0097,  0.0042,  0.0012],\n",
      "        [ 0.0211, -0.0907,  0.0087,  0.0214,  0.0085,  0.0093],\n",
      "        [ 0.0142, -0.0888,  0.0086,  0.0219,  0.0094,  0.0095],\n",
      "        [ 0.0246, -0.0429,  0.0086,  0.0106,  0.0049,  0.0019]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.0078, -0.0919,  0.0086,  0.0183,  0.0082,  0.0097],\n",
      "        [ 0.0092, -0.0974,  0.0086,  0.0212,  0.0090,  0.0107],\n",
      "        [ 0.0118, -0.0980,  0.0085,  0.0233,  0.0102,  0.0109],\n",
      "        [ 0.0157, -0.0906,  0.0087,  0.0197,  0.0081,  0.0093],\n",
      "        [ 0.0076, -0.0927,  0.0084,  0.0159,  0.0072,  0.0095]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(all_poses_t[0,:5])\n",
    "print(all_inv_poses_t[0,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = all_poses_t.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ate_bs = []\n",
    "ate_fs = []\n",
    "\n",
    "i=0\n",
    "#for i in range(k):\n",
    "\n",
    "idx = torch.arange(i, N, k)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0314, -0.0452,  0.0081,  0.0153,  0.0062,  0.0026], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(all_poses_t[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous src\n",
    "b_pose = all_poses_t[1, idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([98, 6])\n",
      "tensor([ 0.0220, -0.0847,  0.0087,  0.0214,  0.0090,  0.0085], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(b_pose.shape)\n",
    "print(b_pose[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_pose = b_pose.cumsum(dim=0) # [n,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([98, 6])\n",
      "tensor([ 0.0220, -0.0847,  0.0087,  0.0214,  0.0090,  0.0085], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(b_pose.shape)\n",
    "print(b_pose[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f68d0851490>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(b_pose[:,3].cpu().numpy(), b_pose[:,4].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch17]",
   "language": "python",
   "name": "conda-env-pytorch17-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
